{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jiaming Lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Confusion Matrix (45pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (4pt) Show the confusion matrix for M1 and M2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M1: Yes for simolestes vorax, No for other marine dinosaurs\n",
    "\n",
    "|            | No(predict) | Yes(predict)               |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| No(actual)        | 3         | 2           |\n",
    "| Yes(actual)        | 1      | 4               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M2: Yes for simolestes vorax, No for other marine dinosaurs\n",
    "\n",
    "|            | No(predict) | Yes(predict)               |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| No(actual)        | 2         | 3           |\n",
    "| Yes(actual)        | 0      | 5               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (5pt) Compute accuracy, precision, recall, and F-score for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M1: A: 0.7, P: 0.6667, R: 0.8, F-score: 0.7273\n",
    "\n",
    "M2: A: 0.7, P: 0.625, R: 1, F-score: 0.769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (6pt) Prof Smith is going to publish her paper and wants you to give the final results tomorrow. Which of these two models, M1 or M2 will you recommend her? Explain to her."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will recommend M2 for her. The reason is that both models have same precentage correctness in prediction and M1 has a not too significantly higher accuracy when predict it is simolestes vorax than M2, but M2 can predict every simolestes vorax correct if it really is. Besides, M2 performs better when we combine previous two comparisions together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (4pt) Show the confusion matrices for M3 and M4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M3: Yes for poisoneus mushrooms, No for edible mushrooms\n",
    "\n",
    "|            | No(predict) | Yes(predict)               |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| No(actual)        | 4         | 3           |\n",
    "| Yes(actual)        | 0      | 3               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M4: Yes for poisoneus mushrooms, No for edible mushrooms\n",
    "\n",
    "|            | No(predict) | Yes(predict)               |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| No(actual)        | 7         | 0           |\n",
    "| Yes(actual)        | 1      | 2               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. (5pt) Compute the accuracy, precision, recall for both models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M3: A: 0.7, P 0.5, R: 1\n",
    "\n",
    "M4: A: 0.9, P 1, R: 0.667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. (6pt) Johanknecht wants to commission the AI system tomorrow. Which model would you recommend her to use? Explain your reasoning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will recommend her M3 model, because although its accuracy is lower than M4, but it can predict every poisoneus mushroom correct if it is, which is more important than accuracy because we don't want to see people eat poisoneus mushrooms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. (4pt) Show the confusion matrices for M5 and M6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M5: Yes for guilty, No for innocent\n",
    "\n",
    "|            | No(predict) | Yes(predict)               |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| No(actual)        | 3         | 2           |\n",
    "| Yes(actual)        | 1      | 4               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M6: Yes for guilty, No for innocent\n",
    "\n",
    "|            | No(predict) | Yes(predict)               |\n",
    "| :---        |    :----:   |          ---: |\n",
    "| No(actual)        | 5         | 0           |\n",
    "| Yes(actual)        | 3      | 2               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. (5pt) Compute the accuracy, precision, recall for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M5: A: 0.7, P: 0.667, R: 0.8\n",
    "                \n",
    "M6: A: 0.7, P: 1, R: 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. (6pt) Johanknecht wants to commission the AI system tomorrow. Which model would you recommend her to use? Explain your reasoning!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will recommend to her M5, because both modles have same accuracy, but M5 predicts much better if the defendants is guilty, and we don't want to see those guilty defendants still active in the society"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Cross-validate to the best model (55pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (2pt) Load the data. Ensure you understand the variables well enough (but no need to learn their biological meaning). We recommend to consult the uploaded doc file.\n",
    "\n",
    "#### Remove the id variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius.mean</th>\n",
       "      <th>texture.mean</th>\n",
       "      <th>perimeter.mean</th>\n",
       "      <th>area.mean</th>\n",
       "      <th>smoothness.mean</th>\n",
       "      <th>compactness.mean</th>\n",
       "      <th>concavity.mean</th>\n",
       "      <th>concpoints.mean</th>\n",
       "      <th>symmetry.mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius.worst</th>\n",
       "      <th>texture.worst</th>\n",
       "      <th>perimeter.worst</th>\n",
       "      <th>area.worst</th>\n",
       "      <th>smoothness.worst</th>\n",
       "      <th>compactness.worst</th>\n",
       "      <th>concavity.worst</th>\n",
       "      <th>concpoints.worst</th>\n",
       "      <th>symmetry.worst</th>\n",
       "      <th>fracdim.worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius.mean  texture.mean  perimeter.mean  area.mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness.mean  compactness.mean  concavity.mean  concpoints.mean  \\\n",
       "0          0.11840           0.27760          0.3001          0.14710   \n",
       "1          0.08474           0.07864          0.0869          0.07017   \n",
       "2          0.10960           0.15990          0.1974          0.12790   \n",
       "3          0.14250           0.28390          0.2414          0.10520   \n",
       "4          0.10030           0.13280          0.1980          0.10430   \n",
       "\n",
       "   symmetry.mean  ...  radius.worst  texture.worst  perimeter.worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area.worst  smoothness.worst  compactness.worst  concavity.worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concpoints.worst  symmetry.worst  fracdim.worst  \n",
       "0            0.2654          0.4601        0.11890  \n",
       "1            0.1860          0.2750        0.08902  \n",
       "2            0.2430          0.3613        0.08758  \n",
       "3            0.2575          0.6638        0.17300  \n",
       "4            0.1625          0.2364        0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = pd.read_csv(\"wdbc.csv.bz2\")\n",
    "wc = wc.drop([\"id\"], axis=1)\n",
    "wc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (2pt) Create your outcome vector y. While LogisticRegression can easily handle string labels B and M, the f1_score cannot. So we recommend you to convert the diagnosis into a numeric 1/0 label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc[\"y\"] =  wc[\"diagnosis\"]\n",
    "wc[\"y\"].loc[wc[\"y\"] == \"M\"] = \"1\"\n",
    "wc[\"y\"].loc[wc[\"y\"] == \"B\"] = \"0\"\n",
    "y = wc[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. (4pt) Create the design matrix X that contains three arbitrary columns from among your features. I recommend to use .iloc, e.g. X = data.iloc[:,[1,5,24]].values to make a design matrix from these three columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wc.iloc[:,[1,2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (6pt) Fit a logistic regression model predicting y using this design matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LogisticRegression()\n",
    "_ = m.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. (9pt) Compute the predicted outcomes, and display the confusion matrix and F-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[337,  20],\n",
       "       [ 32, 180]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = m.predict(X)\n",
    "confusion_matrix(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8737864077669903"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [int(numeric_string) for numeric_string in y]\n",
    "yhat = [int(numeric_string) for numeric_string in yhat]\n",
    "f1_score(y, yhat)\n",
    "# The F-score is 0.8737864077669903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. (9pt) What do you think, what is the most appropriate measure here? Why is F-score a good way to test the models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will say recall, because is important here to predict right if a person has cancer. F-score is always a good way because it combines both recall and precision, so it is good method to see how models work overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. (9pt) Cross-validate the model goodness using F-score as the outcome. (use 5-fold or more) Now it is time to check all possible 3-feature models. You can do three nested loops that run over the columns, create X out of those columns, and repeat the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8733951787980809\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression()\n",
    "_ = m.fit(X, y)\n",
    "cv = cross_val_score(m, X, y, scoring=\"f1\", cv=5)\n",
    "print(cv.mean())\n",
    "# The F-score is 0.8733951787980809"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. (9pt) Loop over all 3-feature combinations and:\n",
    "\n",
    "#### (a) at the corresponding logistic regression model\n",
    "#### (b) cross-validate the F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LogisticRegression()\n",
    "comb = np.array([])\n",
    "f1s = np.array([])\n",
    "\n",
    "for i in range(1, 29):\n",
    "    for j in range(i+1,30):\n",
    "        for k in range(j+1,31):\n",
    "            X = wc.iloc[:,[i,j,k]]\n",
    "            _ = m.fit(X, y)\n",
    "            cv = cross_val_score(m, X, y, scoring=\"f1\", cv=5)\n",
    "            comb = np.append(comb, str(i)+\",\"+str(j)+\",\"+str(k))\n",
    "            f1s = np.append(f1s, cv.mean())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([20], dtype=int64),)\n",
      "0.9367686074693806\n",
      "1,2,23\n"
     ]
    }
   ],
   "source": [
    "index = np.where(f1s == np.amax(f1s))\n",
    "print(index)\n",
    "print(f1s[20])\n",
    "print(comb[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. (5pt) Finally, tell what is your best model and its F-score and accuracy. Which three features did you include?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.9367686074693806\n",
      "Accuracy: 0.9543238627542306\n",
      "radius.mean texture.mean perimeter.worst\n"
     ]
    }
   ],
   "source": [
    "X = wc.iloc[:,[1,2,23]]\n",
    "cv = cross_val_score(m, X, y, scoring=\"f1\", cv=5)\n",
    "print(\"f1:\", cv.mean())\n",
    "cv = cross_val_score(m, X, y, scoring=\"accuracy\", cv=5)\n",
    "print(\"Accuracy:\", cv.mean())\n",
    "\n",
    "coli = wc.columns[1]\n",
    "colj = wc.columns[2]\n",
    "colk = wc.columns[23]\n",
    "print(coli,colj,colk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is column 1(radius.mean), 2(texture.mean) and 23(perimeter.worst), F-score for this model is 0.9368 and accuracy is 0.9543"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much time did you spend on this PS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I spend 4 hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
